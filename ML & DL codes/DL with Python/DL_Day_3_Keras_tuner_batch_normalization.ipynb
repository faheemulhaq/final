{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c5f0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting keras-tuner\n",
      "  Downloading keras_tuner-1.4.6-py3-none-any.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: keras in c:\\users\\hp\\anaconda3\\envs\\new_env\\lib\\site-packages (from keras-tuner) (2.13.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\anaconda3\\envs\\new_env\\lib\\site-packages (from keras-tuner) (23.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\envs\\new_env\\lib\\site-packages (from keras-tuner) (2.31.0)\n",
      "Collecting kt-legacy (from keras-tuner)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests->keras-tuner) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests->keras-tuner) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests->keras-tuner) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\envs\\new_env\\lib\\site-packages (from requests->keras-tuner) (2023.7.22)\n",
      "Downloading keras_tuner-1.4.6-py3-none-any.whl (128 kB)\n",
      "   ---------------------------------------- 0.0/128.9 kB ? eta -:--:--\n",
      "   --- ------------------------------------ 10.2/128.9 kB ? eta -:--:--\n",
      "   ------------------- -------------------- 61.4/128.9 kB 1.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 128.9/128.9 kB 1.5 MB/s eta 0:00:00\n",
      "Installing collected packages: kt-legacy, keras-tuner\n",
      "Successfully installed keras-tuner-1.4.6 kt-legacy-1.0.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: There was an error checking the latest version of pip.\n"
     ]
    }
   ],
   "source": [
    "pip install keras-tuner\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af35cca8",
   "metadata": {},
   "source": [
    "# 1.Build a deep learning model to classify the mnist digits dataset with Batch Normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b9d1b3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " batch_normalization (Batch  (None, 128)               512       \n",
      " Normalization)                                                  \n",
      "                                                                 \n",
      " activation (Activation)     (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_1 (Bat  (None, 128)               512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " activation_1 (Activation)   (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 119306 (466.04 KB)\n",
      "Trainable params: 118794 (464.04 KB)\n",
      "Non-trainable params: 512 (2.00 KB)\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "750/750 [==============================] - 6s 6ms/step - loss: 0.2557 - accuracy: 0.9260 - val_loss: 0.1380 - val_accuracy: 0.9582\n",
      "Epoch 2/10\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.1040 - accuracy: 0.9687 - val_loss: 0.0956 - val_accuracy: 0.9703\n",
      "Epoch 3/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0693 - accuracy: 0.9781 - val_loss: 0.0974 - val_accuracy: 0.9701\n",
      "Epoch 4/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0538 - accuracy: 0.9829 - val_loss: 0.1048 - val_accuracy: 0.9680\n",
      "Epoch 5/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0421 - accuracy: 0.9869 - val_loss: 0.0835 - val_accuracy: 0.9759\n",
      "Epoch 6/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0338 - accuracy: 0.9898 - val_loss: 0.0917 - val_accuracy: 0.9722\n",
      "Epoch 7/10\n",
      "750/750 [==============================] - 4s 6ms/step - loss: 0.0266 - accuracy: 0.9914 - val_loss: 0.0927 - val_accuracy: 0.9720\n",
      "Epoch 8/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 0.0861 - val_accuracy: 0.9783\n",
      "Epoch 9/10\n",
      "750/750 [==============================] - 4s 5ms/step - loss: 0.0256 - accuracy: 0.9913 - val_loss: 0.0902 - val_accuracy: 0.9751\n",
      "Epoch 10/10\n",
      "750/750 [==============================] - 5s 6ms/step - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.0935 - val_accuracy: 0.9751\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0836 - accuracy: 0.9767\n",
      "Test accuracy: 0.9767000079154968\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hp\\anaconda3\\envs\\new_env\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# One-hot encode the labels\n",
    "train_labels = to_categorical(train_labels, 10)\n",
    "test_labels = to_categorical(test_labels, 10)\n",
    "\n",
    "# Build the deep learning model with Batch Normalization\n",
    "model = models.Sequential()\n",
    "\n",
    "# Input layer\n",
    "model.add(layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "# Hidden layers with Batch Normalization\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "model.add(layers.Dense(128))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.Activation('relu'))\n",
    "\n",
    "# Output layer\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Display the model summary\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(f'Test accuracy: {test_acc}')\n",
    "\n",
    "# Save the model\n",
    "model.save(\"mnist_model_with_batch_norm.h5\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef112505",
   "metadata": {},
   "source": [
    "# 2.Build a Feed Forward Neural Network for any problems with keras tuner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "472225b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 5 Complete [00h 00m 33s]\n",
      "val_accuracy: 0.10050000250339508\n",
      "\n",
      "Best val_accuracy So Far: 0.10050000250339508\n",
      "Total elapsed time: 00h 02m 30s\n",
      "313/313 [==============================] - 1s 2ms/step - loss: -33961453551616.0000 - accuracy: 0.1000\n",
      "Test accuracy: 0.10000000149011612\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "# Define the model building function\n",
    "def build_model(hp):\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    # Tune the number of hidden layers\n",
    "    for i in range(hp.Int('num_layers', 2, 5)):\n",
    "        # Tune the number of units in each hidden layer\n",
    "        model.add(layers.Dense(units=hp.Int(f'units_{i}', 32, 128, 32),\n",
    "                               activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "# Load a synthetic dataset (adapt this to your specific problem)\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Flatten the images\n",
    "x_train = x_train.reshape((x_train.shape[0], -1))\n",
    "x_test = x_test.reshape((x_test.shape[0], -1))\n",
    "\n",
    "# Define the Keras Tuner RandomSearch tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,  # Number of hyperparameter combinations to try\n",
    "    directory='my_dir',  # Directory to store the search results\n",
    "    project_name='my_project'  # Name for the project\n",
    ")\n",
    "# Perform hyperparameter tuning\n",
    "tuner.search(x_train, y_train, epochs=5, validation_split=0.2)\n",
    "\n",
    "# Get the best model\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "test_loss, test_acc = best_model.evaluate(x_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e9f435",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
